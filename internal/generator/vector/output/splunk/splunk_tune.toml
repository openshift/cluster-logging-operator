[transforms.splunk_hec_timestamp]
type = "remap"
inputs = ["pipelineName"]
source = '''
ts, err = parse_timestamp(._internal.timestamp,"%+")
if err != null {
	log("could not parse timestamp. err=" + err, rate_limit_secs: 0)
} else {
	._internal.timestamp = ts
}
'''

[transforms.splunk_hec_metadata]
type = "remap"
inputs = ["splunk_hec_timestamp"]
source = '''
# Splunk 'source' field detection
if ._internal.log_type == "infrastructure" && ._internal.log_source == "node" {
    ._internal.splunk.source = to_string!(._internal.systemd.u.SYSLOG_IDENTIFIER || "")
}
if ._internal.log_source == "container" {
   	._internal.splunk.source = join!([._internal.kubernetes.namespace_name, ._internal.kubernetes.pod_name, ._internal.kubernetes.container_name], "_")
}
if ._internal.log_type == "audit" {
   ._internal.splunk.source = ._internal.log_source
}
._internal.splunk.sourcetype = "_json"
'''

[sinks.splunk_hec]
type = "splunk_hec_logs"
inputs = ["splunk_hec_metadata"]
endpoint = "https://splunk-web:8088/endpoint"
default_token = "SECRET[kubernetes_secret.vector-splunk-secret/hecToken]"
timestamp_key = "._internal.timestamp"
source = "{{ ._internal.splunk.source }}"
sourcetype = "{{ ._internal.splunk.sourcetype }}"
host_key = "._internal.hostname"
compression = "gzip"

[sinks.splunk_hec.encoding]
codec = "json"
except_fields = ["_internal"]

[sinks.splunk_hec.batch]
max_bytes = 10000000

[sinks.splunk_hec.buffer]
type = "disk"
when_full = "block"
max_size = 268435488

[sinks.splunk_hec.request]
retry_initial_backoff_secs = 20
retry_max_duration_secs = 35