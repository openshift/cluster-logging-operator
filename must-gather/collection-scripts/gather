#!/bin/bash

# Store PIDs of all the subprocesses
pids=()

echo -e "..... Cluster Logging must-gather script started .....\n"

SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )
BASE_COLLECTION_PATH="${1:-/must-gather}"
LOGGING_NS="${2:-openshift-logging}"
LOGFILE_NAME="${3:-gather-debug.log}"
LOGFILE_PATH="${BASE_COLLECTION_PATH}/${LOGFILE_NAME}" # must-gather/gather-debug.log

mkdir -p "${BASE_COLLECTION_PATH}"
cd $BASE_COLLECTION_PATH
echo -e "must-gather logs are located at: '${LOGFILE_PATH}'"

mkdir ${BASE_COLLECTION_PATH}/cache-dir
export KUBECACHEDIR=${BASE_COLLECTION_PATH}/cache-dir

source ${SCRIPT_DIR}/common

# cluster-scoped resources
cluster_resources=(ns/openshift-operator-lifecycle-manager)

# cluster logging operator namespace
cluster_resources+=(ns/$LOGGING_NS)

# elasticsearch operator namespace
cluster_resources+=(ns/openshift-operators-redhat)

# multi-forwarder namespaces
namespaces=$(oc get clf -A -o custom-columns=:.metadata.namespace | sort -u)
for multi in ${namespaces[@]}; do
    if [ "$multi" != $LOGGING_NS ] ; then
      # add to the list of namespaces
      cluster_resources+=(ns/$multi)
      echo "Adding namespace '$multi' to cluster_resources list"

      # get collector resources from the namespace
      ${SCRIPT_DIR}/gather_collection_resources "$BASE_COLLECTION_PATH" "$multi" >> "${LOGFILE_PATH}" 2>&1

      # gather other logging related resources
      ${SCRIPT_DIR}/gather_cluster_logging_operator_resources "$BASE_COLLECTION_PATH" "$multi" >> "${LOGFILE_PATH}" 2>&1 &
      pids+=($!)
    fi
done

# cluster-scoped resources
cluster_resources+=(nodes)
cluster_resources+=(clusterroles)
cluster_resources+=(clusterrolebindings)
cluster_resources+=(persistentvolumes)
cluster_resources+=(clusterversion)
cluster_resources+=(machineconfigpool)
cluster_resources+=(customresourcedefinitions)

log "-BEGIN inspecting CRs..." >> "${LOGFILE_PATH}"
for cr in "${cluster_resources[@]}" ; do
  log "BEGIN inspecting CR ${cr} ..." >> "${LOGFILE_PATH}"
  oc adm inspect --cache-dir=${KUBECACHEDIR} --dest-dir="${BASE_COLLECTION_PATH}" "${cr}"  >> "${LOGFILE_PATH}" 2>&1 &
  pids+=($!)
  log "END inspecting CR ${cr} ..." >> "${LOGFILE_PATH}"
done
log "END inspecting CRs..." >> "${LOGFILE_PATH}"

# namespace-scoped resources
resources=(pods)
resources+=(roles)
resources+=(rolebindings)
resources+=(configmaps)
resources+=(serviceaccounts)
resources+=(events)
resources+=(clusterlogging)
resources+=(clusterlogforwarder)
resources+=(installplans)
resources+=(subscriptions)
resources+=(clusterserviceversions)
resources+=(logfilemetricexporter)

log "BEGIN inspecting namespaces ..." >> "${LOGFILE_PATH}"

for namespace in "${cluster_resources[@]}" ; do
  # grab all our namespaces -- openshift-logging, openshift-operator-lifecycle-manager, openshift-operators-redhat
  # should also include any multi-forwarder namespaces found above
  if [[ $namespace == ns/* ]]; then
    ns=${namespace#ns/}  # remove "ns/" prefix
    for resource in "${resources[@]}" ; do
      log "BEGIN inspecting namespace ${ns}/${resource} ..." >> "${LOGFILE_PATH}"
      oc adm inspect --cache-dir=${KUBECACHEDIR} --dest-dir="${BASE_COLLECTION_PATH}" -n "$ns" "${resource}"  >> "${LOGFILE_PATH}" 2>&1 &
      pids+=($!)
      log "END inspecting namespace ${ns}/${resource} ..." >> "${LOGFILE_PATH}"
    done
  fi

done
log "END inspecting namespaces ..." >> "${LOGFILE_PATH}"


default_clo_found="$(oc -n "$LOGGING_NS" get deployment cluster-logging-operator --ignore-not-found --no-headers)"

if [ "$default_clo_found" != "" ] ; then
  log "BEGIN gathering default CLO resources ..." >> "${LOGFILE_PATH}"
  ${SCRIPT_DIR}/gather_cluster_logging_operator_resources "$BASE_COLLECTION_PATH" "$LOGGING_NS" >> "${LOGFILE_PATH}" 2>&1 &
  pids+=($!)
  ${SCRIPT_DIR}/gather_collection_resources "$BASE_COLLECTION_PATH" >> "${LOGFILE_PATH}" 2>&1 &
  pids+=($!)
  log "END gathering default CLO resources ..." >> "${LOGFILE_PATH}"
else
  log "Skipping collection inspection.  No default CLO found" >> "${LOGFILE_PATH}" 2>&1
fi

found_es="$(oc -n $LOGGING_NS get elasticsearch elasticsearch --ignore-not-found --no-headers)"
found_lokistack="$(oc -n $LOGGING_NS get lokistack.loki.grafana.com --ignore-not-found --no-headers)"
if [ "$found_es" != "" ] || [ "$found_lokistack" != "" ] ; then
  # Call per component gather scripts
  if [ "$found_es" != "" ] ; then
    log "BEGIN gathering EO resources ..." >> "${LOGFILE_PATH}"
    ${SCRIPT_DIR}/gather_elasticsearch_operator_resources "$BASE_COLLECTION_PATH" >> "${LOGFILE_PATH}" 2>&1 &
    pids+=($!)
    ${SCRIPT_DIR}/gather_logstore_resources "$BASE_COLLECTION_PATH" "elasticsearch" >> "${LOGFILE_PATH}" 2>&1 &
    pids+=($!)
  fi

  if [ "$found_lokistack" != "" ] ; then
    log "BEGIN gathering lokistack resources ..." >> "${LOGFILE_PATH}"
    ${SCRIPT_DIR}/gather_logstore_resources "$BASE_COLLECTION_PATH" "lokistack" >> "${LOGFILE_PATH}" 2>&1 &
    pids+=($!)
  fi

  found="$(oc -n $LOGGING_NS get kibana kibana --ignore-not-found --no-headers)"
  if [ "$found" != "" ] ; then
    KUBECACHEDIR=${BASE_COLLECTION_PATH}/cache-dir ${SCRIPT_DIR}/gather_visualization_resources "$BASE_COLLECTION_PATH" >> "${LOGFILE_PATH}" 2>&1
  fi
  log "END gathering logstorage resources ..." >> "${LOGFILE_PATH}"
else
  log "Skipping logstorage inspection.  No deployment found" >> "${LOGFILE_PATH}" 2>&1
fi

# Check if PID array has any values, if so, wait for them to finish
if [ ${#pids[@]} -ne 0 ]; then
    echo "Waiting on subprocesses to finish execution."
    wait "${pids[@]}"
fi

exit 0
