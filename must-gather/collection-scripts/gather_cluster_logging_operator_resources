#!/bin/bash
SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )
source ${SCRIPT_DIR}/common

# Expect base collection path as an argument
BASE_COLLECTION_PATH=$1
NAMESPACE=${2:-openshift-logging}

log "BEGIN <gather_cluster_logging_operator_resources> from namespace: $NAMESPACE ..."

# Use PWD as base path if no argument is passed
if [ "${BASE_COLLECTION_PATH}" = "" ]; then
    BASE_COLLECTION_PATH=$(pwd)
fi

CLO_COLLECTION_PATH="$BASE_COLLECTION_PATH/cluster-logging"
# Adding namespace folders to allow for multi-logging
clo_folder="$CLO_COLLECTION_PATH/clo/$NAMESPACE"

log "Creating namespace directory: $clo_folder"
mkdir -p "$clo_folder"

# We only need these from the openshift-logging namespace
if [ $NAMESPACE == "openshift-logging" ]; then
  log "Gathering data for 'cluster-logging-operator' from namespace: $NAMESPACE"

  pods=$(oc -n $NAMESPACE get pods -l name=cluster-logging-operator -o jsonpath='{.items[*].metadata.name}')
  for pod in $pods
  do
      get_env $pod $clo_folder $NAMESPACE "Dockerfile-.*operator*"
  done

  oc -n $NAMESPACE get deployment cluster-logging-operator -o yaml --cache-dir=${KUBECACHEDIR} > $clo_folder/deployment

  for csv in $(oc -n $NAMESPACE get csv -o name) ; do
    mkdir -p "$(dirname ${clo_folder}/$csv)"
    oc -n $NAMESPACE get "${csv}" -o yaml --cache-dir=${KUBECACHEDIR} > ${clo_folder}/"${csv}.yaml"
  done
fi

log "Gathering any 'vector.toml' from logging namespace: $NAMESPACE"
secret_names=$(oc -n $NAMESPACE get secrets -o custom-columns=:.metadata.name | grep -e '-config')
for name in ${secret_names[@]}; do
  data=$(oc -n $NAMESPACE get secret ${name} -o jsonpath='{.data.vector\.toml}' --ignore-not-found)
  if [ "$data" != "" ] ; then
    echo $data | base64 -d > ${clo_folder}/${name}_vector.toml 2>&1
  fi
done

log "Gathering 'deployments' and 'daemonsets' and 'version' from logging namespace: $NAMESPACE"
csv_name="$(oc -n $NAMESPACE get csv -o name | grep -E 'cluster(-?)logging')"
oc -n $NAMESPACE get deployments -o wide > ${clo_folder}/deployments.txt --cache-dir=${KUBECACHEDIR} 2>&1
oc -n $NAMESPACE get ds -o wide > ${clo_folder}/daemonsets.txt --cache-dir=${KUBECACHEDIR} 2>&1
oc -n $NAMESPACE get "${csv_name}" -o jsonpath='{.spec.displayName}{"/must-gather\n"}{.spec.version}' --cache-dir=${KUBECACHEDIR} > "${clo_folder}/version"

log "Gathering 'logfilemetricexporter' from namespace: $NAMESPACE"
oc -n $NAMESPACE get lfme -o yaml > ${clo_folder}/lfme.yaml 2>&1

log "Checking for legacy es and fluentd resources"
for r in "secret/elasticsearch" "configmap/collector" ; do
  result="$(oc -n $NAMESPACE get $r --ignore-not-found)"
  if [ "$result" != "" ] ; then
    log "Gathering legacy resource '$r'"
    oc -n $NAMESPACE extract $r --to=${clo_folder} --cache-dir=${KUBECACHEDIR}
  fi
done
log "END <gather_cluster_logging_operator_resources> from namespace: $NAMESPACE ..."
